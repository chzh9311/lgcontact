defaults:
  - msdf: sparse
  - data: hoi4d_hand
  - _self_

handvae:
  input_channel: 3
  latent_dim: 64
  hidden_dim: 64
  mano_root: ${data.mano_root}

training_stage: "handvae"
contact_unit: null

debug: true

train:
  lr: 0.0005
  batch_size: 128
  loss_weights:
    w_param: 0.5
    w_recon: 1.0
    w_kl: 0.000001
  vis_every_n_batches: 1000
  param_guided_epoch: 25
  augment: false
  # resume_ckpt: logs/wandb_logs/LG3DContact/GRIDAE-64v2/epoch=4-wcserec.ckpt
  # pretrained_ckpt: logs/checkpoints/gridae/128latent/best-epoch=22-val/total_loss=0.0970.ckpt

val:
  batch_size: 64
  vis_every_n_batches: 500

test:
  n_processes: 16
  n_samples: 64
  batch_size: ${test.n_samples}

checkpoint:
  dirpath: logs/checkpoints/handvae/${handvae.latent_dim}latent/
  filename: best
  save_top_k: 3

trainer: ## For instantiating pytorch-lightning Trainer
  max_epochs: 200
  check_val_every_n_epoch: 2
  log_every_n_steps: 100
  accelerator: gpu
  devices: [0]
  precision: 32
  # enable_progress_bar: true
  enable_model_summary: true
  # strategy: ddp_find_unused_parameters_true
  # limit_train_batches: 100
  # limit_val_batches: 50

run_phase: train
ckpt_path: null

hydra:
  job:
    chdir: false
  run:
    dir: .
  output_subdir: null
  job_logging:
    disable_existing_loggers: false
  hydra_logging:
    disable_existing_loggers: false